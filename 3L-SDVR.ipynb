{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3L_SDVRP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multinomial\n",
    "from scipy.stats import dirichlet\n",
    "from py3dbp import Packer, Bin, Item\n",
    "import math\n",
    "import random\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import neshan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def initVariables():\n",
    "    # \"rnd\" is an object that generate random numbers\n",
    "    rnd = np.random\n",
    "    #\"seed(0)\" is a method that reset (every time), the same random set of numbers\n",
    "    rnd.seed(0)\n",
    "    # Number of collection points\n",
    "    n_customer = 3\n",
    "    # The set of nodes without the depot.\n",
    "    N = [i for i in range(1,n_customer+1)]\n",
    "    # The set of nodes + the depot.\n",
    "    V = [0]+ N\n",
    "    # The Number of cargoes\n",
    "    Cat = 10\n",
    "    # Generating items for each collection point\n",
    "    IT = []\n",
    "    for i in N:\n",
    "        cargo_set_=[]\n",
    "        for j in range (1,Cat + 1):\n",
    "            cargo_set_.append({(i,j):[rnd.randint(1, kk) for kk in [10,10,10,100]]})\n",
    "        IT.append(cargo_set_)\n",
    "    IT_num = [(i,j) for i in N for j in range(1, Cat + 1)]\n",
    "    # Number of Vehicles\n",
    "    nv = 3\n",
    "    # Max volume and Max weight that each vehicle can carry\n",
    "    Container_vehicle = [('vehicle_%d'%kk, rnd.randint(30, 50), rnd.randint(30, 50), rnd.randint(30, 50), rnd.randint(400, 600)) for kk in range(0,nv) ]\n",
    "\n",
    "    # Defining coordinates of collection points\n",
    "    Locations = pd.DataFrame()\n",
    "    xc = [35.730250, 35.716169, 35.716749, 35.736719, 35.766557, 35.767301, 35.696197]\n",
    "    yc = [51.334336, 51.366407, 51.407847, 51.416115, 51.375811, 51.428972, 51.397952]\n",
    "    Locations['Latitude'] = xc\n",
    "    Locations['Longitude'] = yc\n",
    "    locationtuples = [tuple(x) for x in Locations.to_numpy()]\n",
    "    # The number of Routing plans\n",
    "    RP = 10\n",
    "    # Intializing the set of arcs A.\n",
    "    A = [(i,j) for i in V for j in V if i!=j]\n",
    "    # Calculating the distance between each node as non-negative cost of each arc\n",
    "    # using neshan api (Iranian map services provider) for calculating distances between each pair of points\n",
    "    nmaps = neshan.Client(key='service.M4liZxwyxAUcLqA3NNBf4bop845a0FeMJz4I6BhE')\n",
    "    distance_matrix_result = nmaps.distance_matrix(locationtuples,locationtuples)\n",
    "    dist= {(i, j): distance_matrix_result[\"rows\"][i][\"elements\"][j][\"distance\"][\"value\"] for i, j in A}\n",
    "    # Generating historical data wich show how many times each route has been chosen\n",
    "    historical_routes ={(i, j): rnd.randint(1, 100)/100 for i , j in A }\n",
    "    historical_routes_tuples = [historical_routes[i,j] for i, j in historical_routes]\n",
    "    return (n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vehicle Route Planning Module\n",
    "\n",
    "def findRoutPlans(alpha, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples):\n",
    "    \n",
    "    # Drichlet distribution of routes\n",
    "    multinomial_ed=[]\n",
    "    for alpha_inside in alpha:\n",
    "        drichlet_mean = dirichlet.mean(alpha_inside)\n",
    "        multinomial_ed.append(multinomial.rvs(300, drichlet_mean, size=RP*2))\n",
    "    # Finding Edges\n",
    "    init_final_path = []\n",
    "    final_path =[]\n",
    "    for eachroute in multinomial_ed:\n",
    "        semi_final_path = []\n",
    "        for routplansiterator in range(0, len(eachroute)):\n",
    "            sorted_edges=[]\n",
    "            for maxifinder in range(max(eachroute[routplansiterator]), -1, -1):\n",
    "                finded = np.where(eachroute[routplansiterator] == maxifinder)\n",
    "                sorted_edges.append(finded[0])\n",
    "            first_path = []\n",
    "            for sedge in sorted_edges:\n",
    "                for seg in sedge:\n",
    "                    # Checking for duplicate collection points\n",
    "                    if len(first_path) > 0:\n",
    "                        first_elements = [i for i,j in first_path]\n",
    "                        second_elements = [j for i,j in first_path]\n",
    "                        if A[seg][0] not in first_elements and A[seg][1] not in second_elements:\n",
    "                            first_path.append(A[seg])\n",
    "                    else:\n",
    "                        first_path.append(A[seg])\n",
    "            if len(first_path) > n_customer:        \n",
    "                semi_final_path.append(first_path[0:(n_customer + 2)])\n",
    "\n",
    "        # Removing invalid routes\n",
    "        numfailed = []\n",
    "        for rpiterator in range(0,len(semi_final_path)):\n",
    "            starting_point=0\n",
    "            for jkl in semi_final_path[rpiterator]:\n",
    "                starting_point=starting_point+1\n",
    "                for lkj in semi_final_path[rpiterator][starting_point:]:\n",
    "                    if (jkl[1] == lkj[0] and jkl[0] == lkj[1]):\n",
    "                        numfailed.append(rpiterator)\n",
    "        clear_paths = [i for n, i in enumerate(semi_final_path) if n not in numfailed]\n",
    "        init_final_path.append(clear_paths)\n",
    "\n",
    "    # Choosing different paths for every vehicle between existing rouyte plans\n",
    "    d = 0\n",
    "    final_path =[]\n",
    "\n",
    "    for i in range(0,len(init_final_path)):\n",
    "        a = init_final_path[i][d]\n",
    "        final_path.append(a)\n",
    "        for j in range(i+1,min(i+2, len(init_final_path))):\n",
    "            p=[]\n",
    "            for k in range(0, len(init_final_path[j])):\n",
    "                p.append(len(set(a) & set(init_final_path[j][k])))\n",
    "        d = p.index(min(p))\n",
    "    return final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting Module\n",
    "\n",
    "def splitCargoes(alpha_s, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples):\n",
    "    # Drichlet distribution of plans\n",
    "    multinomial_ed_s=[]\n",
    "    for alpha_s_inside in alpha_s:\n",
    "        drichlet_mean_s = dirichlet.mean(alpha_s_inside)\n",
    "        multinomial_ed_s.append(multinomial.rvs(300, drichlet_mean_s, size=1))\n",
    "    \n",
    "    # Choosing Cargoes\n",
    "    final_set = []\n",
    "    \n",
    "    for cargoewclassiterator in range(0, len(multinomial_ed_s)):\n",
    "        sorted_cargoes=[]\n",
    "        for maxfinder in range(max(multinomial_ed_s[cargoewclassiterator][0]), -1, -1):\n",
    "            if maxfinder>-1:\n",
    "                finded_cargoes = np.where(multinomial_ed_s[cargoewclassiterator][0] == maxfinder)\n",
    "                sorted_cargoes.append(finded_cargoes[0])\n",
    "\n",
    "        first_set = []\n",
    "        for hh in sorted_cargoes:\n",
    "            for ff in hh:\n",
    "                try:\n",
    "                    first_set.append(IT[cargoewclassiterator][ff])\n",
    "                except:\n",
    "                    pass\n",
    "        final_set.append([first_set])\n",
    "\n",
    "    # Cargoes for vehicles\n",
    "    set_for_vehicles=[]\n",
    "    \n",
    "    for vehicle_num in range(0,nv):\n",
    "        init_set=[]\n",
    "        for custom_num in range(0,n_customer):\n",
    "            coef = round(len(final_set[custom_num][0])/nv)\n",
    "            if coef == 0:\n",
    "                if vehicle_num<len(final_set[custom_num][0]):\n",
    "                    init_set.append(final_set[custom_num][0][vehicle_num:vehicle_num+1])\n",
    "                else:\n",
    "                    init_set.append(final_set[custom_num][0][vehicle_num*coef:vehicle_num*coef+coef])\n",
    "            else:\n",
    "                init_set.append(final_set[custom_num][0][vehicle_num*coef:vehicle_num*coef+coef])\n",
    "        set_for_vehicles.append(init_set)\n",
    "\n",
    "    return set_for_vehicles, final_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimal 3D Loading Module\n",
    "\n",
    "def loading(Container_vehicle, final_set, n_customer, N, V, Cat, IT, IT_num, nv, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples):\n",
    "    packer = Packer()\n",
    "    # The maximum volum and weight that a container can carry (length, width, height, weight)\n",
    "    # Add bins\n",
    "    packer.add_bin(Bin(Container_vehicle[0],\n",
    "                        Container_vehicle[1],\n",
    "                        Container_vehicle[2],\n",
    "                        Container_vehicle[3],\n",
    "                        Container_vehicle[4]))\n",
    "\n",
    "    # add items to corresponding containers\n",
    "    for customeritems in final_set:\n",
    "        for items in customeritems:\n",
    "            packer.add_item(Item(list(items.keys())[0],\n",
    "                                list(items.values())[0][0],\n",
    "                                list(items.values())[0][1],\n",
    "                                list(items.values())[0][2],\n",
    "                                list(items.values())[0][3]))\n",
    "\n",
    "    packer.pack(number_of_decimals=0)\n",
    "\n",
    "    return packer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to Calculate Fitness Function 1\n",
    "\n",
    "def fitnessFunction_1(pop, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples):\n",
    "    F1=[]\n",
    "    for vehicles in range(0, len(pop)):\n",
    "        route_cost = 0\n",
    "        for i in pop[vehicles]:\n",
    "            route_cost = route_cost + dist[i]\n",
    "        F1.append(route_cost)\n",
    "\n",
    "    return sum(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate Fitness Function 2\n",
    "\n",
    "def fitnessFunction_2(pc_items, pc_bins, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples):\n",
    "\n",
    "    # Calculate each container capacity\n",
    "    containers_weight = [wgh[4] for wgh in Container_vehicle]\n",
    "    containers_volume = [vol[1]*vol[2]*vol[3] for vol in Container_vehicle]\n",
    "\n",
    "    # Calculate all items wgh and vol\n",
    "    items_weight = []\n",
    "    items_volume = []\n",
    "\n",
    "    for boxes in pc_items:\n",
    "        items_weight.append(sum([float(item.weight) for item in boxes]))\n",
    "        items_volume.append(sum([float(item.get_volume()) for item in boxes]))\n",
    "\n",
    "    rvol = sum(items_volume)\n",
    "    rwgh = sum(items_weight)\n",
    "    \n",
    "    rvol_mean = sum(items_volume)/sum(containers_volume)\n",
    "    rwgh_mean = sum(items_weight)/sum(containers_weight)\n",
    "\n",
    "    # Calculate each vehicle bins items wgh and vol\n",
    "    bins_fitteditems_weight = []\n",
    "    bins_fitteditems_volume = []\n",
    "    for contain in pc_bins:\n",
    "        bins_fitteditems_weight.append(sum([float(item.weight) for item in contain[0].items]))\n",
    "        bins_fitteditems_volume.append(sum([float(item.get_volume()) for item in contain[0].items]))\n",
    "\n",
    "    total_fitteditems_wgh = sum(bins_fitteditems_weight)\n",
    "    total_fitteditems_vol = sum(bins_fitteditems_volume)\n",
    "\n",
    "    F2 = rvol + rwgh - total_fitteditems_vol - total_fitteditems_wgh\n",
    "    return F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find index of list\n",
    "\n",
    "def index_of(a,list):\n",
    "    for i in range(0,len(list)):\n",
    "        if list[i] == a:\n",
    "            return i\n",
    "\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sort by values\n",
    "\n",
    "def sort_by_values(list1, values):\n",
    "    sorted_list = []\n",
    "    while(len(sorted_list)!=len(list1)):\n",
    "        if index_of(min(values),values) in list1:\n",
    "            sorted_list.append(index_of(min(values),values))\n",
    "        values[index_of(min(values),values)] = math.inf\n",
    "\n",
    "    return sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate NSGA_II's crowding distance\n",
    "\n",
    "def crowding_distance(values1, values2, front):\n",
    "\n",
    "    distance = [0 for i in range(0,len(front))]\n",
    "    sorted1 = sort_by_values(front, values1[:])\n",
    "    sorted2 = sort_by_values(front, values2[:])\n",
    "    distance[0] = 999999999999999\n",
    "    distance[len(front) - 1] = 999999999999999\n",
    "\n",
    "    for k in range(1,len(front)-1):\n",
    "        if (max(values1)-min(values1) == 0):\n",
    "            distance[k] = 999999999999999\n",
    "        else:\n",
    "            distance[k] = distance[k]+ (values1[sorted1[k+1]] - values2[sorted1[k-1]])/(max(values1)-min(values1))\n",
    "    for k in range(1,len(front)-1):\n",
    "        if (max(values2)-min(values2) == 0):\n",
    "            distance[k] = 999999999999999\n",
    "        else:\n",
    "            distance[k] = distance[k]+ (values2[sorted2[k+1]] - values2[sorted2[k-1]])/(max(values2)-min(values2))\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to carry out NSGA-II's non dominated sort\n",
    "\n",
    "def fast_non_dominated_sort(values1, values2):\n",
    "\n",
    "    S=[[] for i in range(0,len(values1))]\n",
    "    front = [[]]\n",
    "    n=[0 for i in range(0,len(values1))]\n",
    "    rank = [0 for i in range(0, len(values1))]\n",
    "\n",
    "    for p in range(0,len(values1)):\n",
    "        S[p]=[]\n",
    "        n[p]=0\n",
    "        for q in range(0, len(values1)):\n",
    "            if (values1[p] < values1[q] and values2[p] < values2[q]) or (values1[p] <= values1[q] and values2[p] < values2[q]) or (values1[p] < values1[q] and values2[p] <= values2[q]):\n",
    "                if q not in S[p]:\n",
    "                    S[p].append(q)\n",
    "            elif (values1[q] < values1[p] and values2[q] < values2[p]) or (values1[q] <= values1[p] and values2[q] < values2[p]) or (values1[q] < values1[p] and values2[q] <= values2[p]):\n",
    "                n[p] = n[p] + 1\n",
    "        if n[p]==0:\n",
    "            rank[p] = 0\n",
    "            if p not in front[0]:\n",
    "                front[0].append(p)\n",
    "\n",
    "    i = 0\n",
    "    while(front[i] != []):\n",
    "        Q=[]\n",
    "        for p in front[i]:\n",
    "            for q in S[p]:\n",
    "                n[q] =n[q] - 1\n",
    "                if( n[q]==0):\n",
    "                    rank[q]=i+1\n",
    "                    if q not in Q:\n",
    "                        Q.append(q)\n",
    "        i = i+1\n",
    "        front.append(Q)\n",
    "    del front[len(front)-1]\n",
    "    \n",
    "    return front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to carry out the NSGA_II's crossover\n",
    "\n",
    "def crossover(pop1,pop2):\n",
    "\n",
    "    mutation_prob = random.random()\n",
    "\n",
    "    if mutation_prob > 0.8:\n",
    "        pop1, pop2 = mutation(pop1, pop2)\n",
    "    else:\n",
    "        r1 = np.random.randint(0, len(pop1['route']))\n",
    "        r2 = np.random.randint(0, len(pop1['route']))\n",
    "\n",
    "        route_1 = pop1['route'][r1]\n",
    "        route_2 = pop2['route'][r2]\n",
    "        pop1['route'][r1] = route_2\n",
    "        pop2['route'][r2] = route_1\n",
    "\n",
    "        r3 = np.random.randint(0, len(pop1['set'][0]))\n",
    "\n",
    "        for i in range(0,len(pop1['set'])):\n",
    "            set_1 = pop1['set'][i][r3]\n",
    "            set_2 = pop2['set'][i][r3]\n",
    "            pop1['set'][i][r3] = set_2\n",
    "            pop2['set'][i][r3] = set_1\n",
    "\n",
    "    return pop1, pop2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to carry out the mutation operator\n",
    "def mutation(pop1, pop2):\n",
    "    r_ = random.random()\n",
    "    r1 = np.random.randint(1, len(pop1['set']))\n",
    "    r2 = np.random.randint(1, len(pop1['set']))\n",
    "    if r_ > 0.5:\n",
    "        set_1 = pop1['set'][r1]\n",
    "        set_2 = pop1['set'][r2]\n",
    "        pop1['set'][r1] = set_2\n",
    "        pop1['set'][r2] = set_1\n",
    "    else:\n",
    "        set_1 = pop2['set'][r1]\n",
    "        set_2 = pop2['set'][r2]\n",
    "        pop2['set'][r1] = set_2\n",
    "        pop2['set'][r2] = set_1\n",
    "\n",
    "    return pop1, pop2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to init the first population and update the distribution matrix\n",
    "def InitializePopulation(pop_size, max_gen, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples):\n",
    "    print(\"now running function DTSA\")\n",
    "    route_prob = []\n",
    "    for j in range(0, len(Container_vehicle)):\n",
    "        route_prob.append(historical_routes_tuples)\n",
    "    alpha = route_prob  ### alpha is an array of our historical data for each edge\n",
    "\n",
    "    split_prob=[]\n",
    "    for i in range (0, n_customer):\n",
    "        split_prob.append([1 for j in range(0, Cat)])\n",
    "    alpha_s = split_prob     ### alpha_s is an uniform array for splitting plan\n",
    "\n",
    "    pop_size = pop_size\n",
    "    pop = {}\n",
    "    max_gen = max_gen\n",
    "    gen_no = 0\n",
    "    pltF1 = []\n",
    "    pltF2 = []\n",
    "    function1 = []\n",
    "    function2 = []\n",
    "\n",
    "    while(gen_no<max_gen):\n",
    "\n",
    "        # Calculate fitness functions for generated population\n",
    "        for ind in range(0,pop_size):\n",
    "            final_path = findRoutPlans(alpha, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "            set_per_vehic, total_sets = splitCargoes(alpha_s, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "            pc_bins = []\n",
    "            pc_items = []\n",
    "            counter_sets = 0\n",
    "            for vehicle_count in range(0,len(Container_vehicle)):\n",
    "                pc = loading(Container_vehicle[vehicle_count], set_per_vehic[counter_sets], n_customer, N, V, Cat, IT, IT_num, nv, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "                pc_bins.append(pc.bins)\n",
    "                pc_items.append(pc.items)\n",
    "                counter_sets = counter_sets + 1\n",
    "\n",
    "            fitness_1 = fitnessFunction_1(final_path, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "            fitness_2 = fitnessFunction_2(pc_items, pc_bins, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "\n",
    "            pop[ind] = {\n",
    "                        'route': final_path,\n",
    "                        'set': set_per_vehic,\n",
    "                        'pack_bins': pc_bins,\n",
    "                        'pack_items': pc_items,\n",
    "                        'F1': fitness_1,\n",
    "                        'F2': fitness_2\n",
    "                        } \n",
    "\n",
    "        # Best Pareto Front\n",
    "        objective1_values = [float(pop[i]['F1']) for i in range(0,len(pop))]\n",
    "        objective2_values = [float(pop[i]['F2']) for i in range(0,len(pop))]\n",
    "        \n",
    "        # Find index of best route plan\n",
    "        best_route_plan = index_of(min(objective1_values), objective1_values)\n",
    "        # Find index of best splitting plan\n",
    "        best_split_plan = index_of(min(objective2_values), objective2_values)\n",
    "        # Updating routes distribution matrix\n",
    "        for route_min in range(0, len(pop[best_route_plan]['route'])):\n",
    "            for edge in pop[best_route_plan]['route'][route_min]:\n",
    "                index = index_of(edge, A)\n",
    "                alpha[route_min][index] = alpha[route_min][index] + 1\n",
    "        # Updating Splitting distribution matrix\n",
    "        maxcoefficient = len(pop[best_split_plan]['set'])\n",
    "        for plans in pop[best_split_plan]['set']:\n",
    "            maxcoefficient = maxcoefficient -1\n",
    "            for node_min in plans:\n",
    "                if len(node_min) > Cat-2:\n",
    "                    ak = 0\n",
    "                    for clus_1 in node_min :\n",
    "                        ak = ak + 1\n",
    "                        alpha_s[list(clus_1.keys())[0][0] - 1][list(clus_1.keys())[0][1] - 1] = alpha_s[list(clus_1.keys())[0][0] - 1][list(clus_1.keys())[0][1]-1] + (1*maxcoefficient)\n",
    "\n",
    "        function1 = function1 + [i for i in objective1_values]\n",
    "        function2 = function2 + [j for j in objective2_values]\n",
    "\n",
    "        pltF1.append(sum(function1)/len(function1))\n",
    "        pltF2.append(sum(function2)/len(function2))\n",
    "        # pltF1.append(min(function1))\n",
    "        # pltF2.append(min(function2))\n",
    "        \n",
    "\n",
    "        # Plot Fitness functions values\n",
    "\n",
    "        # fit1 = pltF1\n",
    "        # fit2 = pltF2\n",
    "        \n",
    "        # fig = plt.figure()\n",
    "        # ax1 = fig.add_subplot(111)\n",
    "        # ax1.plot(fit1, 'r-')\n",
    "        # ax1.set_ylabel('Fitness_1', color='r')\n",
    "        # for rl in ax1.get_yticklabels():\n",
    "        #     rl.set_color('r')\n",
    "\n",
    "        # ax2 = ax1.twinx()\n",
    "        # ax2.plot(fit2, 'b-')\n",
    "        # ax2.set_ylabel('Fitness_2', color='b')\n",
    "        # for tl in ax2.get_yticklabels():\n",
    "        #     tl.set_color('b')\n",
    "        # plt.ioff()\n",
    "        # plt.ion()\n",
    "        # display.clear_output(wait=True)\n",
    "\n",
    "        # plt.show()\n",
    "        # display.display(gen_no)\n",
    "\n",
    "        gen_no = gen_no + 1\n",
    "\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to do NSGA_II to find the best plan\n",
    "\n",
    "def NSGA_II_main(pop, max_gen, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples):\n",
    "        print(\"now running function NSGA_II\")\n",
    "        max_gen = max_gen\n",
    "        gen_no = 0\n",
    "        pltF1 = []\n",
    "        pltF2 = []\n",
    "        pltF1min = []\n",
    "        pltF2min = []\n",
    "        function1 = []\n",
    "        function2 = []\n",
    "        pop_size = 2*len(pop)\n",
    "\n",
    "        route_prob = []\n",
    "        for j in range(0, len(Container_vehicle)):\n",
    "                route_prob.append([1 for i in range(0, len(historical_routes_tuples))])\n",
    "        alpha = route_prob  ### alpha is an array of our historical data for each edge\n",
    "\n",
    "        split_prob=[]\n",
    "        for i in range (0, n_customer):\n",
    "                split_prob.append([1 for i in range(0, Cat)])\n",
    "        alpha_s = split_prob     ### alpha_s is an uniform array for splitting plan\n",
    "\n",
    "        for ind in range(int(pop_size/2), pop_size):\n",
    "                final_path = findRoutPlans(alpha, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "                set_per_vehic, total_sets = splitCargoes(alpha_s, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "                pc_bins = []\n",
    "                pc_items = []\n",
    "                counter_sets = 0\n",
    "                for vehicle_count in range(0,len(Container_vehicle)):\n",
    "                        pc = loading(Container_vehicle[vehicle_count], set_per_vehic[counter_sets], n_customer, N, V, Cat, IT, IT_num, nv, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "                        \n",
    "                        pc_bins.append(pc.bins)\n",
    "                        pc_items.append(pc.items)\n",
    "                        counter_sets = counter_sets + 1\n",
    "\n",
    "                fitness_1 = fitnessFunction_1(final_path, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "                fitness_2 = fitnessFunction_2(pc_items, pc_bins, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "\n",
    "                pop[ind] = {\n",
    "                        'route': final_path,\n",
    "                        'set': set_per_vehic,\n",
    "                        'pack_bins': pc_bins,\n",
    "                        'pack_items': pc_items,\n",
    "                        'F1': fitness_1,\n",
    "                        'F2': fitness_2\n",
    "                        }\n",
    "        while(gen_no<max_gen):\n",
    "\n",
    "                # None dominated sorting for the generated population\n",
    "                objective1_values = [float(pop[i]['F1']) for i in range(0,len(pop))]\n",
    "                objective2_values = [float(pop[i]['F2']) for i in range(0,len(pop))]\n",
    "                non_dominated_sorted_solution = fast_non_dominated_sort(objective1_values[:],objective2_values[:])\n",
    "                \n",
    "                # Calculate Crowding distance for fronts\n",
    "                crowding_distance_values=[]\n",
    "\n",
    "                for i in range(0,len(non_dominated_sorted_solution)):\n",
    "                        crowding_distance_values.append(crowding_distance(objective1_values[:], objective2_values[:], non_dominated_sorted_solution[i][:]))\n",
    "\n",
    "                # Generating new population through crossover nd mutation\n",
    "                pop2 = {}\n",
    "                for i in range(0, len(pop)):\n",
    "                        pop2[i] = pop[i]\n",
    "\n",
    "                ll=len(pop)\n",
    "                while(len(pop2) < 2*pop_size):\n",
    "                        a1 = random.randint(0,pop_size-1)\n",
    "                        b1 = random.randint(0,pop_size-1)\n",
    "                        \n",
    "                        # Crossover and mutation\n",
    "                        off_1, off_2 = crossover(pop[a1],pop[b1])\n",
    "                        pop2[ll] = off_1\n",
    "                        pop2[ll+1] = off_2\n",
    "\n",
    "                        pc1_bins = []\n",
    "                        pc1_items = []\n",
    "                        pc2_bins = []\n",
    "                        pc2_items = []\n",
    "                        counter_sets = 0\n",
    "                        \n",
    "                        # Calculate fitness functions for newly generated offsprings\n",
    "                        for vehicle_count in range(0,len(Container_vehicle)):\n",
    "                                pc_1 = loading(Container_vehicle[vehicle_count], pop2[ll]['set'][counter_sets], n_customer, N, V, Cat, IT, IT_num, nv, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "                                pc_2 = loading(Container_vehicle[vehicle_count], pop2[ll+1]['set'][counter_sets], n_customer, N, V, Cat, IT, IT_num, nv, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "                                pc1_bins.append(pc_1.bins)\n",
    "                                pc1_items.append(pc_1.items)\n",
    "                                pc2_bins.append(pc_2.bins)\n",
    "                                pc2_items.append(pc_2.items)\n",
    "                                counter_sets = counter_sets + 1\n",
    "\n",
    "                        pop2[ll]['pack_bins'] = pc1_bins\n",
    "                        pop2[ll]['pack_items'] = pc1_items\n",
    "                        pop2[ll+1]['pack_bins'] = pc2_bins\n",
    "                        pop2[ll+1]['pack_items'] = pc2_items\n",
    "\n",
    "                        fitness_1_off_1 = fitnessFunction_1(pop2[ll]['route'], n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "                        fitness_2_off_1 = fitnessFunction_2(pop2[ll]['pack_items'], pop2[ll]['pack_bins'], n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "                        fitness_1_off_2 = fitnessFunction_1(pop2[ll+1]['route'], n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "                        fitness_2_off_2 = fitnessFunction_2(pop2[ll+1]['pack_items'], pop2[ll+1]['pack_bins'], n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "\n",
    "                        pop2[ll]['F1'] = fitness_1_off_1\n",
    "                        pop2[ll]['F2'] = fitness_2_off_1\n",
    "                        pop2[ll+1]['F1'] = fitness_1_off_2\n",
    "                        pop2[ll+1]['F2'] = fitness_2_off_2\n",
    "                        ll= ll + 2\n",
    "                \n",
    "                #None dominated sorting of new generation\n",
    "                objective1_values2 = [float(pop2[i]['F1']) for i in range(0,len(pop2))]\n",
    "                objective2_values2 = [float(pop2[i]['F2']) for i in range(0,len(pop2))]\n",
    "                non_dominated_sorted_solution2 = fast_non_dominated_sort(objective1_values2[:],objective2_values2[:])\n",
    "                \n",
    "                # Crowding distance of new generation\n",
    "                crowding_distance_values2=[]\n",
    "                for i in range(0,len(non_dominated_sorted_solution2)):\n",
    "                        crowding_distance_values2.append(crowding_distance(objective1_values2[:],objective1_values2[:],non_dominated_sorted_solution2[i][:]))\n",
    "                \n",
    "                # Ranking Solutions and replacing older solutions\n",
    "                new_solution= []\n",
    "                for i in range(0,len(non_dominated_sorted_solution2)):\n",
    "                        non_dominated_sorted_solution2_1 = [index_of(non_dominated_sorted_solution2[i][j],non_dominated_sorted_solution2[i] ) for j in range(0,len(non_dominated_sorted_solution2[i]))]\n",
    "                        front22 = sort_by_values(non_dominated_sorted_solution2_1[:], crowding_distance_values2[i][:])\n",
    "                        front = [non_dominated_sorted_solution2[i][front22[j]] for j in range(0,len(non_dominated_sorted_solution2[i]))]\n",
    "                        front.reverse()\n",
    "                        for value in front:\n",
    "                                new_solution.append(value)\n",
    "                                if(len(new_solution)==pop_size):\n",
    "                                        break\n",
    "                        if (len(new_solution) == pop_size):\n",
    "                                break\n",
    "                # Replacing Older solutions\n",
    "                pop.clear()\n",
    "                for sol in range(0, len(new_solution)):\n",
    "                        pop[sol] = pop2[new_solution[sol]]\n",
    "                \n",
    "                # Store fitness values\n",
    "                function1 = function1 + [i * 1 for i in objective1_values]\n",
    "                function2 = function2 + [j * 1 for j in objective2_values]\n",
    "\n",
    "                pltF1.append(min(function1))\n",
    "                pltF2.append(min(function2))\n",
    "\n",
    "                # pl.clf()\n",
    "                # pl.scatter(function1,function2)\n",
    "\n",
    "                # display.clear_output(wait=True)\n",
    "                # display.display(pl.gcf())\n",
    "                # display.display(gen_no)\n",
    "\n",
    "                # Plot Fitness functions values\n",
    "\n",
    "                # fit1 = pltF1\n",
    "                # fit2 = pltF2\n",
    "                \n",
    "                # fig = plt.figure()\n",
    "                # ax1 = fig.add_subplot(111)\n",
    "                # ax1.plot(fit1, 'r-')\n",
    "                # ax1.set_ylabel('Fitness_1', color='r')\n",
    "                # for rl in ax1.get_yticklabels():\n",
    "                #         rl.set_color('r')\n",
    "\n",
    "                # ax2 = ax1.twinx()\n",
    "                # ax2.plot(fit2, 'b-')\n",
    "                # ax2.set_ylabel('Fitness_2', color='b')\n",
    "                # for tl in ax2.get_yticklabels():\n",
    "                #         tl.set_color('b')\n",
    "                # plt.ioff()\n",
    "                # plt.ion()\n",
    "                # display.clear_output(wait=True)\n",
    "\n",
    "                # plt.show()\n",
    "                # # pl.clf()\n",
    "                # # pl.scatter(function1,function2)\n",
    "                # display.display(gen_no)\n",
    "                \n",
    "                gen_no = gen_no + 1\n",
    "        return pop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the route on roads network\n",
    "\n",
    "def sequencefinder(final_pop, locationtuples, n_customer):\n",
    "\n",
    "    def sequence(final_pop, locationtuples, n_customer):\n",
    "        route_sequence =[0]\n",
    "        k=0\n",
    "        for al in range(0,20):\n",
    "            for i,j in final_pop:\n",
    "                if i == k:\n",
    "                    route_sequence.append(j)\n",
    "                    k=j\n",
    "        sequence_locations_init=[]\n",
    "        for i in route_sequence[0:n_customer+2] :\n",
    "            sequence_locations_init.append(tuple(locationtuples[i]))\n",
    "        return sequence_locations_init\n",
    "\n",
    "    sequence_locations = sequence(final_pop[0]['route'][0], locationtuples, n_customer)\n",
    "\n",
    "    depot = []\n",
    "    dep=0\n",
    "    for d in sequence_locations:\n",
    "        if d == sequence_locations[0]  and dep>0 and dep<(n_customer+1) :\n",
    "            depot.append(dep)\n",
    "        dep = dep + 1\n",
    "\n",
    "    if len(depot)>0:\n",
    "        sequence_locations = sequence(final_pop[0]['route'][1], locationtuples, n_customer)\n",
    "\n",
    "    return sequence_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "now running function DTSA\nnow running function NSGA_II\nnow running function DTSA\nnow running function NSGA_II\n"
    }
   ],
   "source": [
    "n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples = initVariables()\n",
    "# Running the DTSA Module for producing routing and splitting plans\n",
    "initpop = InitializePopulation(10, 5, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "# Running The NSGA_II for finding the optimum solutions for SD-VRP problem\n",
    "final_pop = NSGA_II_main(initpop, 5, n_customer, N, V, Cat, IT, IT_num, nv, Container_vehicle, locationtuples, RP, A, nmaps, dist, historical_routes, historical_routes_tuples)\n",
    "# Saving the route for showing on the map\n",
    "final_routing_plan=[]\n",
    "sequence_locations = sequencefinder(final_pop, locationtuples, n_customer)\n",
    "directions_result = nmaps.directions(sequence_locations[0], sequence_locations[-1], sequence_locations[1:-1])\n",
    "final_routing_plan.append(directions_result[0][\"overview_polyline\"][\"points\"])\n",
    "\n",
    "# Calculate remained Items that has not been collected yet\n",
    "whole_remain_items=[]\n",
    "remained_items = {}\n",
    "remained_items_txt_vehicle = {}\n",
    "for b in final_pop[0]['pack_bins']:\n",
    "    whole_cargoes = {}\n",
    "    unfitted_items_txt={}\n",
    "    fitted_items_txt={}\n",
    "    for unfit in b[0].unfitted_items:\n",
    "        remained_items[unfit.name] = unfit.get_dimension()\n",
    "        unfitted_items_txt[str(unfit.name)] = unfit.string()\n",
    "    for fit in b[0].items:\n",
    "        fitted_items_txt[str(fit.name)] = fit.string()\n",
    "    whole_cargoes['Fitted_Items'] = fitted_items_txt\n",
    "    whole_cargoes['Unfitted_Items'] = unfitted_items_txt\n",
    "    remained_items_txt_vehicle[b[0].string()] = whole_cargoes\n",
    "\n",
    "remained_collection_points =[0]\n",
    "for i,j in remained_items:\n",
    "    if i not in remained_collection_points:\n",
    "        remained_collection_points.append(i)\n",
    "remained_collection_points = sorted(remained_collection_points)\n",
    "\n",
    "whole_remain_items.append(remained_items_txt_vehicle)\n",
    "\n",
    "# Looping through the whole algorithm again untill all cargies are allocated\n",
    "while (len(remained_collection_points)>2):\n",
    "    # remove unremained collection point from historical data\n",
    "    new_historical_routes_tuples=[]\n",
    "    for i,j in historical_routes:\n",
    "        if i in remained_collection_points and j in remained_collection_points:\n",
    "            new_historical_routes_tuples.append(historical_routes[i,j])\n",
    "\n",
    "    # remove unremained collection point from edges\n",
    "    new_A = [(i,j) for i in remained_collection_points for j in remained_collection_points if i!=j]\n",
    "\n",
    "    # remove allocated cargoes\n",
    "    IT_new = []\n",
    "    for i in N:\n",
    "        cargo_set_2=[]\n",
    "        for j in range (1,Cat + 1):\n",
    "            if (i, j) in remained_items:\n",
    "                cargo_set_2.append(IT[i-1][j-1])\n",
    "        IT_new.append(cargo_set_2)\n",
    "\n",
    "    initpop_2 = InitializePopulation(10, 5, len(remained_collection_points)-1, N, V, Cat, IT_new, IT_num, nv, Container_vehicle, locationtuples,RP, new_A, nmaps, dist, historical_routes, new_historical_routes_tuples)\n",
    "    final_pop_2 = NSGA_II_main(initpop_2, 5, len(remained_collection_points)-1, N, V, Cat, IT_new, IT_num, nv, Container_vehicle, locationtuples, RP, new_A, nmaps, dist, historical_routes, new_historical_routes_tuples)\n",
    "\n",
    "    sequence_locations_2 = sequencefinder(final_pop_2, locationtuples, len(remained_collection_points)-1)\n",
    "    directions_result_2 = nmaps.directions(sequence_locations_2[0], sequence_locations_2[-1], sequence_locations_2[1:-1])\n",
    "\n",
    "    final_routing_plan.append(directions_result_2[0][\"overview_polyline\"][\"points\"])\n",
    "\n",
    "    # Calculate remained Items that has not been collected yet\n",
    "    remained_items = {}\n",
    "    remained_items_txt_vehicle = {}\n",
    "    for b in final_pop_2[0]['pack_bins']:\n",
    "        whole_cargoes = {}\n",
    "        unfitted_items_txt={}\n",
    "        fitted_items_txt={}\n",
    "        for unfit in b[0].unfitted_items:\n",
    "            remained_items[unfit.name] = unfit.get_dimension()\n",
    "            unfitted_items_txt[str(unfit.name)] = unfit.string()\n",
    "        for fit in b[0].items:\n",
    "            fitted_items_txt[str(fit.name)] = fit.string()\n",
    "        whole_cargoes['Fitted_Items'] = fitted_items_txt\n",
    "        whole_cargoes['Unfitted_Items'] = unfitted_items_txt\n",
    "        remained_items_txt_vehicle[b[0].string()] = whole_cargoes\n",
    "\n",
    "    remained_collection_points =[0]\n",
    "    for i,j in remained_items:\n",
    "        if i not in remained_collection_points:\n",
    "            remained_collection_points.append(i)\n",
    "    remained_collection_points = sorted(remained_collection_points)\n",
    "    whole_remain_items.append(remained_items_txt_vehicle)\n",
    "\n",
    "# overviewPath = directions_result[0][\"overview_polyline\"][\"points\"]        \n",
    "finalresult =[final_routing_plan, locationtuples, whole_remain_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[['aqayEyfixH}RdBwK]cCiXnBaWnDqRb@_MtB_Btd@yItn@BpEeBdH_I|CyAfR_B~Bj@AhCoBHsIaSoZo]~AuTrSgSlIeJmk@dj@ai@{j@aAqC|EeQzFyd@vKk_@jEyVFqc@yGmSMiIrCmGlJaIhVYsEeTjIiGpMpAsC{OuBSwZiDyNyH[ie@kWxBmS~EiCuNuR`GkAwG_Ao@kF~GDjBbA`ApHqB|BnMpg@yLnClL|D~BrOvQfNvHjFbUwIxRqNbNiDxIPvGbHvUCta@uEdXoKx]}En`@cJz_@z@jTvCzNH|d@lIxYL`q@cAzn@aA~ByRdA',\n  'aqayEyfixHu_@fAcCiXbIsx@jh@yLtn@BtS_OfR_B~Bj@AhCoBHsIaSoZo]~AuTrSgSlIeJmk@dj@o|@y{@aMqAsaAtHqOcGuJyO{CySwFqjBuAi|AgDi`@`AkMpJ_PhPiMte@mC|`@|Fp@pT}G`JhAlDpHqB|BnMpg@yLnClLpUvUfNvHjFbUwIxRqNbNiDxItHn^Cta@gd@jyBrEfd@H|d@lIxYu@|`BaA~ByRdA'],\n [(35.73025, 51.334336),\n  (35.716169, 51.366407),\n  (35.716749, 51.407847),\n  (35.736719, 51.416115),\n  (35.766557, 51.375811),\n  (35.767301, 51.428972),\n  (35.696197, 51.397952)],\n [{'vehicle_0(36x49x44, max_weight:442) vol(77616)': {'Fitted_Items': {'(2, 2)': '(2, 2)(3x1x1, weight: 37) pos([0, 0, 0]) rt(0) vol(3)',\n     '(1, 10)': \"(1, 10)(2x1x5, weight: 24) pos([Decimal('3'), 0, 0]) rt(0) vol(10)\",\n     '(1, 7)': \"(1, 7)(4x6x1, weight: 83) pos([Decimal('5'), 0, 0]) rt(0) vol(24)\",\n     '(3, 5)': \"(3, 5)(1x3x8, weight: 60) pos([Decimal('9'), 0, 0]) rt(0) vol(24)\",\n     '(3, 7)': \"(3, 7)(4x3x4, weight: 21) pos([Decimal('10'), 0, 0]) rt(0) vol(48)\",\n     '(1, 4)': \"(1, 4)(2x7x8, weight: 88) pos([Decimal('14'), 0, 0]) rt(0) vol(112)\",\n     '(2, 7)': \"(2, 7)(5x5x7, weight: 69) pos([Decimal('16'), 0, 0]) rt(0) vol(175)\",\n     '(2, 9)': \"(2, 9)(9x5x4, weight: 59) pos([Decimal('21'), 0, 0]) rt(0) vol(180)\"},\n    'Unfitted_Items': {'(3, 9)': \"(3, 9)(7x9x3, weight: 52) pos([Decimal('21'), 0, Decimal('4')]) rt(0) vol(189)\"}},\n   'vehicle_1(49x38x43, max_weight:430) vol(80066)': {'Fitted_Items': {'(3, 8)': '(3, 8)(2x3x2, weight: 37) pos([0, 0, 0]) rt(0) vol(12)',\n     '(3, 3)': \"(3, 3)(5x3x1, weight: 94) pos([Decimal('2'), 0, 0]) rt(0) vol(15)\",\n     '(1, 1)': \"(1, 1)(6x1x4, weight: 68) pos([Decimal('7'), 0, 0]) rt(0) vol(24)\",\n     '(3, 6)': \"(3, 6)(3x3x4, weight: 95) pos([Decimal('13'), 0, 0]) rt(0) vol(36)\",\n     '(1, 8)': \"(1, 8)(4x9x2, weight: 30) pos([Decimal('16'), 0, 0]) rt(0) vol(72)\",\n     '(2, 4)': \"(2, 4)(5x9x2, weight: 66) pos([Decimal('20'), 0, 0]) rt(0) vol(90)\",\n     '(2, 5)': \"(2, 5)(8x4x7, weight: 12) pos([Decimal('25'), 0, 0]) rt(0) vol(224)\",\n     '(2, 3)': \"(2, 3)(6x6x7, weight: 18) pos([Decimal('33'), 0, 0]) rt(0) vol(252)\"},\n    'Unfitted_Items': {'(1, 6)': \"(1, 6)(9x5x4, weight: 81) pos([Decimal('20'), 0, Decimal('2')]) rt(0) vol(180)\"}},\n   'vehicle_2(32x33x32, max_weight:507) vol(33792)': {'Fitted_Items': {'(3, 10)': '(3, 10)(1x1x7, weight: 1) pos([0, 0, 0]) rt(0) vol(7)',\n     '(2, 6)': \"(2, 6)(3x1x4, weight: 54) pos([Decimal('1'), 0, 0]) rt(0) vol(12)\",\n     '(3, 4)': \"(3, 4)(4x3x1, weight: 22) pos([Decimal('4'), 0, 0]) rt(0) vol(12)\",\n     '(3, 1)': \"(3, 1)(2x6x4, weight: 65) pos([Decimal('8'), 0, 0]) rt(0) vol(48)\",\n     '(2, 1)': \"(2, 1)(4x3x8, weight: 29) pos([Decimal('10'), 0, 0]) rt(0) vol(96)\",\n     '(2, 8)': \"(2, 8)(5x4x5, weight: 53) pos([Decimal('14'), 0, 0]) rt(0) vol(100)\",\n     '(1, 5)': \"(1, 5)(9x2x6, weight: 26) pos([Decimal('19'), 0, 0]) rt(0) vol(108)\",\n     '(1, 9)': \"(1, 9)(4x4x8, weight: 33) pos([Decimal('28'), 0, 0]) rt(0) vol(128)\",\n     '(1, 3)': \"(1, 3)(8x7x9, weight: 89) pos([Decimal('8'), Decimal('6'), 0]) rt(0) vol(504)\"},\n    'Unfitted_Items': {}}},\n  {'vehicle_0(36x49x44, max_weight:442) vol(77616)': {'Fitted_Items': {'(1, 6)': '(1, 6)(9x5x4, weight: 81) pos([0, 0, 0]) rt(0) vol(180)'},\n    'Unfitted_Items': {}},\n   'vehicle_1(49x38x43, max_weight:430) vol(80066)': {'Fitted_Items': {},\n    'Unfitted_Items': {}},\n   'vehicle_2(32x33x32, max_weight:507) vol(33792)': {'Fitted_Items': {},\n    'Unfitted_Items': {}}}]]"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "finalresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ploting Sample Route plan\n",
    "# import networkx as nx \n",
    "# G = nx.DiGraph()\n",
    "# G.add_edges_from(final_pop[0]['route'][0]) \n",
    "\n",
    "# plt.figure(figsize =(9, 9)) \n",
    "# nx.draw_networkx(G, with_label = True, node_color ='blue') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we just have to replace the IT variable with remained_items and run the whole algorithms againt to collect the remained items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python_defaultSpec_1596788245051"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}